{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrDEr5o8ypNR"
   },
   "source": [
    "# Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AOiUiHLkypNT",
    "outputId": "5933711e-86a0-4280-f983-97a9ef42b867"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import PatchTSTForPretraining\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TREGjqdXypNW"
   },
   "source": [
    "## Data preprocessing\n",
    " - The earth FM expects 48 timesteps per pixel. Make sure to aggregate appropriately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9nnS_pOZypNW",
    "outputId": "66f99869-99ae-44e2-a384-dc7d3632294b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>crop_type</th>\n",
       "      <th>red</th>\n",
       "      <th>nir</th>\n",
       "      <th>swir16</th>\n",
       "      <th>swir22</th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "      <th>rededge1</th>\n",
       "      <th>rededge2</th>\n",
       "      <th>rededge3</th>\n",
       "      <th>nir08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cameroon_agro-industrial_zones_1027296.3541211...</td>\n",
       "      <td>2023-01-28</td>\n",
       "      <td>1.027296e+06</td>\n",
       "      <td>442622.0456</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>946.683944</td>\n",
       "      <td>1687.203380</td>\n",
       "      <td>1866.737465</td>\n",
       "      <td>1569.879437</td>\n",
       "      <td>530.815211</td>\n",
       "      <td>750.355493</td>\n",
       "      <td>1217.850704</td>\n",
       "      <td>1533.812958</td>\n",
       "      <td>1672.096901</td>\n",
       "      <td>1811.185352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cameroon_agro-industrial_zones_1027296.3541211...</td>\n",
       "      <td>2025-02-26</td>\n",
       "      <td>1.027296e+06</td>\n",
       "      <td>442622.0456</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>673.653371</td>\n",
       "      <td>2464.291011</td>\n",
       "      <td>1874.200562</td>\n",
       "      <td>1200.038202</td>\n",
       "      <td>439.839888</td>\n",
       "      <td>698.465169</td>\n",
       "      <td>1225.969101</td>\n",
       "      <td>2178.980337</td>\n",
       "      <td>2426.982584</td>\n",
       "      <td>2619.929775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cameroon_agro-industrial_zones_1027296.3541211...</td>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>1.027296e+06</td>\n",
       "      <td>442622.0456</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>948.154366</td>\n",
       "      <td>2183.624789</td>\n",
       "      <td>2084.355493</td>\n",
       "      <td>1502.390423</td>\n",
       "      <td>605.953803</td>\n",
       "      <td>850.432113</td>\n",
       "      <td>1292.897465</td>\n",
       "      <td>1932.809014</td>\n",
       "      <td>2127.110423</td>\n",
       "      <td>2313.249577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cameroon_agro-industrial_zones_1027296.3541211...</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>1.027296e+06</td>\n",
       "      <td>442622.0456</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>994.290141</td>\n",
       "      <td>1650.518310</td>\n",
       "      <td>2020.218028</td>\n",
       "      <td>1626.656338</td>\n",
       "      <td>569.026479</td>\n",
       "      <td>786.678310</td>\n",
       "      <td>1263.043380</td>\n",
       "      <td>1513.849577</td>\n",
       "      <td>1616.574085</td>\n",
       "      <td>1776.781972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cameroon_agro-industrial_zones_1027296.3541211...</td>\n",
       "      <td>2025-02-21</td>\n",
       "      <td>1.027296e+06</td>\n",
       "      <td>442622.0456</td>\n",
       "      <td>cocoa</td>\n",
       "      <td>628.101408</td>\n",
       "      <td>2732.930704</td>\n",
       "      <td>1814.214648</td>\n",
       "      <td>1160.927324</td>\n",
       "      <td>488.134648</td>\n",
       "      <td>709.317183</td>\n",
       "      <td>1087.594930</td>\n",
       "      <td>2301.493521</td>\n",
       "      <td>2639.037746</td>\n",
       "      <td>2762.190986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           unique_id        time  \\\n",
       "0  Cameroon_agro-industrial_zones_1027296.3541211...  2023-01-28   \n",
       "1  Cameroon_agro-industrial_zones_1027296.3541211...  2025-02-26   \n",
       "2  Cameroon_agro-industrial_zones_1027296.3541211...  2021-01-28   \n",
       "3  Cameroon_agro-industrial_zones_1027296.3541211...  2022-01-03   \n",
       "4  Cameroon_agro-industrial_zones_1027296.3541211...  2025-02-21   \n",
       "\n",
       "              x            y crop_type         red          nir       swir16  \\\n",
       "0  1.027296e+06  442622.0456     cocoa  946.683944  1687.203380  1866.737465   \n",
       "1  1.027296e+06  442622.0456     cocoa  673.653371  2464.291011  1874.200562   \n",
       "2  1.027296e+06  442622.0456     cocoa  948.154366  2183.624789  2084.355493   \n",
       "3  1.027296e+06  442622.0456     cocoa  994.290141  1650.518310  2020.218028   \n",
       "4  1.027296e+06  442622.0456     cocoa  628.101408  2732.930704  1814.214648   \n",
       "\n",
       "        swir22        blue       green     rededge1     rededge2     rededge3  \\\n",
       "0  1569.879437  530.815211  750.355493  1217.850704  1533.812958  1672.096901   \n",
       "1  1200.038202  439.839888  698.465169  1225.969101  2178.980337  2426.982584   \n",
       "2  1502.390423  605.953803  850.432113  1292.897465  1932.809014  2127.110423   \n",
       "3  1626.656338  569.026479  786.678310  1263.043380  1513.849577  1616.574085   \n",
       "4  1160.927324  488.134648  709.317183  1087.594930  2301.493521  2639.037746   \n",
       "\n",
       "         nir08  \n",
       "0  1811.185352  \n",
       "1  2619.929775  \n",
       "2  2313.249577  \n",
       "3  1776.781972  \n",
       "4  2762.190986  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# This is a dummy dataset\n",
    "# N.B. This df is for illustration only and should only be used to get an understanding of the problem. This data is completely fictious.\n",
    "train_data = pd.read_csv('Final_input.csv')\n",
    "train_data = train_data.dropna()\n",
    "\n",
    "counts = train_data['unique_id'].value_counts()\n",
    "\n",
    "# Filter unique_ids that appear more than once\n",
    "ids_to_keep = counts[counts > 1].index\n",
    "\n",
    "# Keep only rows where unique_id appears more than once\n",
    "train_data = train_data[train_data['unique_id'].isin(ids_to_keep)]\n",
    "train_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Create Train Data -----------\n",
    "# bands = {\n",
    "#     \"red\": \"B4\",\n",
    "#     \"nir\": \"B8\",\n",
    "#     \"swir16\": \"B11\",\n",
    "#     \"swir22\": \"B12\",\n",
    "#     \"blue\": \"B2\",\n",
    "#     \"green\": \"B3\",\n",
    "#     \"rededge1\": \"B5\",\n",
    "#     \"rededge2\": \"B6\",\n",
    "#     \"rededge3\": \"B7\",\n",
    "#     \"nir08\": \"B8A\",\n",
    "# }\n",
    "\n",
    "# reversed_bands = {v: k for k, v in bands.items()}\n",
    "\n",
    "\n",
    "# import glob\n",
    "# files = glob.glob('Input_csvs/*')\n",
    "# # print(files)\n",
    "\n",
    "\n",
    "# def fix_data(dataframes) :\n",
    "#     combined_df = pd.DataFrame(columns=train_data.columns)\n",
    "\n",
    "#     for df_name in dataframes:\n",
    "        \n",
    "#         dataframe = pd.read_csv(df_name)\n",
    "\n",
    "#         if 'crop_type' not in dataframe.columns:\n",
    "#             dataframe['crop_type'] = 'rubber'\n",
    "#         try:\n",
    "#             dataframe.rename(columns=reversed_bands, inplace=True)\n",
    "#             dataframe = dataframe[train_data.columns]\n",
    "#             combined_df = pd.concat([combined_df, dataframe], ignore_index=True)\n",
    "\n",
    "#         except:\n",
    "#             print(df_name)\n",
    "#     return combined_df\n",
    "\n",
    "# combined = fix_data(files)\n",
    "# print(combined.head())\n",
    "# combined.to_csv(\"Final_input.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "V4bCSsQnypNX",
    "outputId": "594604d8-e26f-4ce2-85ac-6f91d95e787d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>red</th>\n",
       "      <th>nir</th>\n",
       "      <th>swir16</th>\n",
       "      <th>swir22</th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "      <th>rededge1</th>\n",
       "      <th>rededge2</th>\n",
       "      <th>rededge3</th>\n",
       "      <th>nir08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_01FHV4</td>\n",
       "      <td>2018-01-03 10:59:22.851</td>\n",
       "      <td>-296455.0</td>\n",
       "      <td>846395.0</td>\n",
       "      <td>0.2920</td>\n",
       "      <td>0.3686</td>\n",
       "      <td>0.4173</td>\n",
       "      <td>0.3869</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>0.2708</td>\n",
       "      <td>0.3211</td>\n",
       "      <td>0.3555</td>\n",
       "      <td>0.3752</td>\n",
       "      <td>0.3862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_01FHV4</td>\n",
       "      <td>2018-01-03 10:59:22.851</td>\n",
       "      <td>-296455.0</td>\n",
       "      <td>846395.0</td>\n",
       "      <td>0.2920</td>\n",
       "      <td>0.3686</td>\n",
       "      <td>0.4173</td>\n",
       "      <td>0.3869</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>0.2708</td>\n",
       "      <td>0.3211</td>\n",
       "      <td>0.3555</td>\n",
       "      <td>0.3752</td>\n",
       "      <td>0.3862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_01FHV4</td>\n",
       "      <td>2018-02-12 10:59:25.232</td>\n",
       "      <td>-296455.0</td>\n",
       "      <td>846395.0</td>\n",
       "      <td>0.3510</td>\n",
       "      <td>0.3426</td>\n",
       "      <td>0.4817</td>\n",
       "      <td>0.4577</td>\n",
       "      <td>0.2538</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.3484</td>\n",
       "      <td>0.3588</td>\n",
       "      <td>0.3628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_01FHV4</td>\n",
       "      <td>2018-02-12 10:59:25.232</td>\n",
       "      <td>-296455.0</td>\n",
       "      <td>846395.0</td>\n",
       "      <td>0.3510</td>\n",
       "      <td>0.3426</td>\n",
       "      <td>0.4817</td>\n",
       "      <td>0.4577</td>\n",
       "      <td>0.2538</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.3484</td>\n",
       "      <td>0.3588</td>\n",
       "      <td>0.3628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_01FHV4</td>\n",
       "      <td>2018-03-14 10:59:24.436</td>\n",
       "      <td>-296455.0</td>\n",
       "      <td>846395.0</td>\n",
       "      <td>0.5312</td>\n",
       "      <td>0.6296</td>\n",
       "      <td>0.6643</td>\n",
       "      <td>0.5882</td>\n",
       "      <td>0.5244</td>\n",
       "      <td>0.5308</td>\n",
       "      <td>0.6016</td>\n",
       "      <td>0.6217</td>\n",
       "      <td>0.6401</td>\n",
       "      <td>0.6404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id                     time         x         y     red     nir  \\\n",
       "0  ID_01FHV4  2018-01-03 10:59:22.851 -296455.0  846395.0  0.2920  0.3686   \n",
       "1  ID_01FHV4  2018-01-03 10:59:22.851 -296455.0  846395.0  0.2920  0.3686   \n",
       "2  ID_01FHV4  2018-02-12 10:59:25.232 -296455.0  846395.0  0.3510  0.3426   \n",
       "3  ID_01FHV4  2018-02-12 10:59:25.232 -296455.0  846395.0  0.3510  0.3426   \n",
       "4  ID_01FHV4  2018-03-14 10:59:24.436 -296455.0  846395.0  0.5312  0.6296   \n",
       "\n",
       "   swir16  swir22    blue   green  rededge1  rededge2  rededge3   nir08  \n",
       "0  0.4173  0.3869  0.2488  0.2708    0.3211    0.3555    0.3752  0.3862  \n",
       "1  0.4173  0.3869  0.2488  0.2708    0.3211    0.3555    0.3752  0.3862  \n",
       "2  0.4817  0.4577  0.2538  0.2914    0.3684    0.3484    0.3588  0.3628  \n",
       "3  0.4817  0.4577  0.2538  0.2914    0.3684    0.3484    0.3588  0.3628  \n",
       "4  0.6643  0.5882  0.5244  0.5308    0.6016    0.6217    0.6401  0.6404  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Cq7fi0rWypNX",
    "outputId": "16ea2d78-f5f3-4fc6-b941-13005402cd00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crop_type\n",
       "rubber      40423\n",
       "palm_oil    37921\n",
       "cocoa       21100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['crop_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xWLQg5ibypNY",
    "outputId": "1894978e-90c3-475d-e6ef-338372985074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total timesteps per pixel: 4456\n",
      "Minimum timesteps per pixel: 2\n",
      "Maximum timesteps per pixel: 96\n",
      "Average timesteps per pixel: 22.316876122082586\n"
     ]
    }
   ],
   "source": [
    "timesteps_per_pixel = train_data.groupby('unique_id').size()  #count the timesteps per pixel since model expects 48 timesteps per pixel\n",
    "\n",
    "print(\"Total timesteps per pixel:\", len(timesteps_per_pixel))\n",
    "print(\"Minimum timesteps per pixel:\", timesteps_per_pixel.min())\n",
    "print(\"Maximum timesteps per pixel:\", timesteps_per_pixel.max())\n",
    "print(\"Average timesteps per pixel:\", timesteps_per_pixel.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lPQl8JTaypNZ",
    "outputId": "5ef9d399-9fda-4067-f6c9-d546f9719637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total timesteps per pixel: 10523\n",
      "Minimum timesteps per pixel: 74\n",
      "Maximum timesteps per pixel: 740\n",
      "Average timesteps per pixel: 114.33155944122399\n"
     ]
    }
   ],
   "source": [
    "test_pixel = test_data.groupby('unique_id').size()  #count the timesteps per pixel since model expects 48 timesteps per pixel\n",
    "\n",
    "print(\"Total timesteps per pixel:\", len(test_pixel))\n",
    "print(\"Minimum timesteps per pixel:\", test_pixel.min())\n",
    "print(\"Maximum timesteps per pixel:\", test_pixel.max())\n",
    "print(\"Average timesteps per pixel:\", test_pixel.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "h8euYClRypNZ"
   },
   "outputs": [],
   "source": [
    "bands = ['red', 'nir', 'swir16', 'swir22', 'blue', 'green','rededge1', 'rededge2', 'rededge3', 'nir08']  # The spectral bands in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "50XaeYi_ypNa"
   },
   "outputs": [],
   "source": [
    "# You can have different ways to aggregate data to the required timesteps\n",
    "# Below we have use interpolation, but remember it might introduce noise\n",
    "\n",
    "from scipy.interpolate import CubicSpline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_with_interpolation(df, bands):\n",
    "    all_results = []\n",
    "    has_crop_type = 'crop_type' in df.columns\n",
    "\n",
    "    for pixel_id, group in df.groupby('unique_id'):\n",
    "        group = group.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "        # if len(group) < 2:\n",
    "        #     # Not enough points to interpolate; either skip or handle differently\n",
    "        #     print(f\"Skipping unique_id {pixel_id} because it has less than 2 time points.\")\n",
    "        #     continue\n",
    "\n",
    "        if len(group) == 48:\n",
    "            keep_cols = ['unique_id', 'x', 'y'] + bands\n",
    "            if has_crop_type:\n",
    "                keep_cols.insert(1, 'crop_type')\n",
    "\n",
    "            clean_group = group[keep_cols].copy()\n",
    "            clean_group['timestep'] = range(48)\n",
    "            all_results.append(clean_group)\n",
    "        else:\n",
    "            new_rows = []\n",
    "            interpolated_bands = {}\n",
    "            old_times = np.arange(len(group))\n",
    "            new_times = np.linspace(0, len(group) - 1, 48)\n",
    "\n",
    "            for band in bands:\n",
    "                spline = CubicSpline(old_times, group[band].values)\n",
    "                interpolated_bands[band] = spline(new_times)\n",
    "\n",
    "            for i in range(48):\n",
    "                new_row = {\n",
    "                    'unique_id': pixel_id,\n",
    "                    'timestep': i,\n",
    "                    'x': group['x'].iloc[0],\n",
    "                    'y': group['y'].iloc[0]\n",
    "                }\n",
    "                if has_crop_type:\n",
    "                    new_row['crop_type'] = group['crop_type'].iloc[0]\n",
    "\n",
    "                for band in bands:\n",
    "                    new_row[band] = interpolated_bands[band][i]\n",
    "\n",
    "                new_rows.append(new_row)\n",
    "\n",
    "            all_results.append(pd.DataFrame(new_rows))\n",
    "\n",
    "    final_df = pd.concat(all_results, ignore_index=True)\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN or Inf count per specified columns:\n",
      "red         0\n",
      "nir         0\n",
      "swir16      0\n",
      "swir22      0\n",
      "blue        0\n",
      "green       0\n",
      "rededge1    0\n",
      "rededge2    0\n",
      "rededge3    0\n",
      "nir08       0\n",
      "dtype: int64\n",
      "\n",
      "Rows with NaN or Inf in specified columns:\n",
      "Empty DataFrame\n",
      "Columns: [unique_id, time, x, y, crop_type, red, nir, swir16, swir22, blue, green, rededge1, rededge2, rededge3, nir08]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "cols_to_check = bands\n",
    "\n",
    "# Check for NaN in those columns\n",
    "nan_mask = train_data[cols_to_check].isna()\n",
    "\n",
    "# Check for inf or -inf in those columns\n",
    "inf_mask = ~np.isfinite(train_data[cols_to_check])\n",
    "\n",
    "# Combine both masks\n",
    "bad_mask = nan_mask | inf_mask\n",
    "\n",
    "# Count bad values per selected column\n",
    "print(\"NaN or Inf count per specified columns:\")\n",
    "print(bad_mask.sum())\n",
    "\n",
    "# Show rows where any of those columns have bad values\n",
    "bad_rows = train_data[bad_mask.any(axis=1)]\n",
    "print(\"\\nRows with NaN or Inf in specified columns:\")\n",
    "print(bad_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "i6FZuK4yypNa"
   },
   "outputs": [],
   "source": [
    "preprocessed_train_data = preprocess_with_interpolation(train_data, bands)\n",
    "preprocessed_test_data = preprocess_with_interpolation(test_data, bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cdzK5LdUypNb",
    "outputId": "a995de28-1fa6-42b0-ea87-a75212b03453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum timesteps per pixel: 48\n",
      "Maximum timesteps per pixel: 48\n"
     ]
    }
   ],
   "source": [
    "train_pixel = preprocessed_train_data.groupby('unique_id').size()  #count the timesteps per pixel since model expects 48 timesteps per pixel\n",
    "\n",
    "print(\"Minimum timesteps per pixel:\", train_pixel.min())\n",
    "print(\"Maximum timesteps per pixel:\", train_pixel.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-6I-F3xypNb"
   },
   "source": [
    "# MODELLING\n",
    "- The earth FM was pretrained on a vast amount of Sentinel 2 unlabeled timeseries data, built on [PATCHTST](https://huggingface.co/docs/transformers/en/model_doc/patchtst#transformers.PatchTSTForPretraining) architecture.\n",
    "- The pretrained model can be used in different ways: finetuning though supervised classification, as a feature extractor etc.\n",
    "\n",
    "Download the models on hugging face\n",
    " - [600K](https://huggingface.co/AminiTech/FM-600K)\n",
    " - [18M](https://huggingface.co/AminiTech/fm-v2-28M)\n",
    "\n",
    "The model expects a dataset and its mask as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1FW8cp5jypNb"
   },
   "outputs": [],
   "source": [
    "# use the model as a feature extractor for RF model\n",
    "def extract_patch_embeddings(model, past_values):\n",
    "    past_observed_mask = ~torch.isnan(past_values)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model.model(\n",
    "            past_values=past_values,\n",
    "            past_observed_mask=past_observed_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        embeddings = model_output.last_hidden_state\n",
    "        all_patches = embeddings[:, :, 1:, :]\n",
    "        final_embeddings = all_patches.mean(dim=(1, 2))  # average of all patch level embeddings\n",
    "        return final_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "lRKlBL0XypNc"
   },
   "outputs": [],
   "source": [
    "hf_token = os.getenv('HUGGINGFACE_HUB_TOKEN')\n",
    "MODEL_PATH = \"AminiTech/fm-v2-28M\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FfN_AFsoypNc"
   },
   "outputs": [],
   "source": [
    "class CropDataset(Dataset):\n",
    "    def __init__(self, sequences, labels, unique_ids):\n",
    "        self.sequences = torch.FloatTensor(sequences)\n",
    "        self.labels = labels\n",
    "        self.unique_ids = unique_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'sequence': self.sequences[idx],\n",
    "            'unique_id': self.unique_ids[idx]\n",
    "        }\n",
    "        if self.labels is not None:\n",
    "            item['label'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "\n",
    "def prepare_sequences_from_df(df):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    unique_ids = []\n",
    "    has_labels = 'crop_type' in df.columns\n",
    "\n",
    "    for unique_id, group in df.groupby('unique_id'):\n",
    "        spectral_data = group[bands].values\n",
    "        sequences.append(spectral_data)\n",
    "        unique_ids.append(unique_id)\n",
    "\n",
    "        if has_labels:\n",
    "            labels.append(group['crop_type'].iloc[0])\n",
    "\n",
    "    sequences = np.array(sequences)\n",
    "\n",
    "    print(f\"Prepared {len(sequences)} sequences\")\n",
    "\n",
    "    if has_labels:\n",
    "        print(f\"Crop distribution:\")\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        for crop, count in zip(unique, counts):\n",
    "            print(f\"  {crop}: {count}\")\n",
    "    else:\n",
    "        labels = None\n",
    "\n",
    "    return sequences, labels, unique_ids\n",
    "\n",
    "def extract_embeddings_from_dataloader(model, dataloader):\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "    all_ids = []\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            sequences = batch['sequence'].to(device)\n",
    "            embeddings = extract_patch_embeddings(model, sequences)\n",
    "\n",
    "            all_embeddings.append(embeddings.cpu())  # Move to CPU before collecting\n",
    "            all_ids.extend(batch['unique_id'])\n",
    "\n",
    "    return torch.cat(all_embeddings, dim=0), all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oBaXtrRUypNc",
    "outputId": "c0b6cdc3-1878-4071-b0b6-4aaaaa574634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 4456 sequences\n",
      "Crop distribution:\n",
      "  cocoa: 601\n",
      "  palm_oil: 2390\n",
      "  rubber: 1465\n"
     ]
    }
   ],
   "source": [
    "train_seq, train_labels, train_ids = prepare_sequences_from_df(preprocessed_train_data)\n",
    "train_dataset = CropDataset(train_seq, train_labels, train_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rcRH8m3-ypNc",
    "outputId": "ef923441-6259-442b-986a-b8d308d16d98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sequences shape: (4456, 48, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train sequences shape:\", train_seq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "V7gO8sbFypNc",
    "outputId": "ddcd6436-1522-48d2-e102-07fab00f279c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 10523 sequences\n"
     ]
    }
   ],
   "source": [
    "test_seq, test_labels, test_ids = prepare_sequences_from_df(preprocessed_test_data)\n",
    "test_dataset = CropDataset(test_seq, test_labels, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1BOBTmARypNd",
    "outputId": "510dfdae-4342-47a3-e1b7-228a17898749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sequences shape: (10523, 48, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test sequences shape:\", test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FRCoflX2ypNd"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sIri9nXJypNd",
    "outputId": "55c7418a-4f69-428f-a1e2-8919c4ed67e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchTSTForPretraining(\n",
       "  (model): PatchTSTModel(\n",
       "    (scaler): PatchTSTScaler(\n",
       "      (scaler): PatchTSTMeanScaler()\n",
       "    )\n",
       "    (patchifier): PatchTSTPatchify()\n",
       "    (masking): PatchTSTMasking()\n",
       "    (encoder): PatchTSTEncoder(\n",
       "      (embedder): PatchTSTEmbedding(\n",
       "        (input_embedding): Linear(in_features=12, out_features=512, bias=True)\n",
       "      )\n",
       "      (positional_encoder): PatchTSTPositionalEncoding(\n",
       "        (positional_dropout): Identity()\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x PatchTSTEncoderLayer(\n",
       "          (self_attn): PatchTSTAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout_path1): Identity()\n",
       "          (norm_sublayer1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_path2): Identity()\n",
       "          (norm_sublayer2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELUActivation()\n",
       "            (2): Identity()\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout_path3): Identity()\n",
       "          (norm_sublayer3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): PatchTSTMaskPretrainHead(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear): Linear(in_features=512, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model = PatchTSTForPretraining.from_pretrained(MODEL_PATH, token=hf_token)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3JCxCw5jypNd"
   },
   "outputs": [],
   "source": [
    "train_embeddings, train_ids = extract_embeddings_from_dataloader(model, train_loader)\n",
    "test_embeddings, test_ids = extract_embeddings_from_dataloader(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Create Embedding Files -----------\n",
    "# torch.save(train_embeddings, 'train_embeddings.pt')\n",
    "# np.save('train_embeddings_ids.npy', train_ids)\n",
    "\n",
    "# torch.save(test_embeddings, 'test_embeddings.pt')\n",
    "# np.save('test_embeddings_ids.npy', test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[ 0.6097,  0.9484,  0.3963,  ...,  0.4032,  0.6007, -0.7055],\n",
      "        [ 0.1650,  0.4639,  0.1910,  ...,  0.2222, -0.3090, -0.2594],\n",
      "        [-0.5103, -0.0295,  0.3583,  ...,  0.1325,  0.2291,  0.2532],\n",
      "        ...,\n",
      "        [-0.3575,  0.3849,  0.3919,  ...,  0.4636,  0.6441,  0.1684],\n",
      "        [-0.2641,  0.1988,  0.4723,  ...,  0.0352,  0.1942, -0.0709],\n",
      "        [-0.1840, -0.0501,  0.4710,  ...,  0.2261,  0.5127,  0.1728]])\n",
      "tensor([[ 0.2932,  0.4967,  0.1392,  ...,  0.5569,  0.3980,  0.5024],\n",
      "        [ 0.2519,  0.4542,  0.5961,  ...,  0.8276,  0.3188,  0.0608],\n",
      "        [ 0.4902, -0.0429,  0.3587,  ...,  0.2537,  0.6006,  0.0621],\n",
      "        ...,\n",
      "        [ 0.6098,  0.2324,  0.4650,  ..., -0.1130,  0.3078, -0.0493],\n",
      "        [ 0.5932,  0.2984,  0.5971,  ...,  0.4384,  0.7716,  0.0991],\n",
      "        [ 0.2171,  0.3540,  0.3130,  ...,  0.3006,  0.5143,  0.0174]])\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = torch.load('train_embeddings.pt')\n",
    "test_embeddings = torch.load('test_embeddings.pt')\n",
    "print(type(train_embeddings))\n",
    "print(train_embeddings)\n",
    "print(test_embeddings)\n",
    "\n",
    "train_ids = np.load('train_embeddings_ids.npy')\n",
    "test_ids = np.load('test_embeddings_ids.npy')\n",
    "print(type(train_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4456\n",
      "['gfw_oil_palm_v20191031_101.98360438863475_1.4347455001548042'\n",
      " 'gfw_oil_palm_v20191031_95.4370086793393_4.944997143503429'\n",
      " 'CIVKokao_-6.913756211067165_6.957262587700001' ...\n",
      " 'gfw_oil_palm_v20191031_103.10146279606863_-1.0080137024203566'\n",
      " 'gfw_oil_palm_v20191031_115.69185185857123_-0.9600121575349476'\n",
      " 'rubber_703']\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids))\n",
    "print(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "DaY3K2oEypNe",
    "outputId": "2f0fa36f-18d9-4e18-c01c-ce787511be28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: Train torch.Size([4456, 512]), Test torch.Size([10523, 512])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embeddings shape: Train {train_embeddings.shape}, Test {test_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "QGERFIy-ypNe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "print(train_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "CY_2M-CaypNe",
    "outputId": "74d80dc8-3d8a-40c4-a573-b2564e662000"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', random_state=42)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(class_weight=\"balanced\", random_state=42, n_estimators=100)\n",
    "rf_model.fit(train_embeddings.numpy(), train_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "TF16XrFlypNe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       unique_id  crop_type_cocoa  crop_type_oil  crop_type_rubber\n",
      "0      ID_EJC3B8             0.13           0.52              0.35\n",
      "1      ID_7K84PG             0.14           0.55              0.31\n",
      "2      ID_PQIQZO             0.11           0.52              0.37\n",
      "3      ID_DW4JFT             0.10           0.67              0.23\n",
      "4      ID_U0I1PZ             0.10           0.52              0.38\n",
      "...          ...              ...            ...               ...\n",
      "10518  ID_UIWZKV             0.11           0.63              0.26\n",
      "10519  ID_ZAXSAZ             0.11           0.60              0.29\n",
      "10520  ID_KG159I             0.13           0.56              0.31\n",
      "10521  ID_XBPSLE             0.13           0.62              0.25\n",
      "10522  ID_YVREWQ             0.11           0.53              0.36\n",
      "\n",
      "[10523 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "test_predictions_encoded = rf_model.predict_proba(test_embeddings.numpy())\n",
    "# print(test_predictions_encoded)\n",
    "# print(label_encoder.classes_)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'unique_id': test_ids,\n",
    "    'crop_type_cocoa': test_predictions_encoded[:,0],\n",
    "    'crop_type_oil': test_predictions_encoded[:,1],\n",
    "    'crop_type_rubber': test_predictions_encoded[:,2]\n",
    "})\n",
    "print(submission)\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CVk3DYOypNe",
    "outputId": "d608169e-070a-4a7d-a5a8-c8860d790248"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (10523, 3) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(test_predictions_encoded)\n\u001b[1;32m      3\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m: test_ids,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m: test_predictions\n\u001b[1;32m      6\u001b[0m })\n\u001b[1;32m      7\u001b[0m submission\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:153\u001b[0m, in \u001b[0;36mLabelEncoder.inverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform labels back to original encoding.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m    Original encoding.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    152\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 153\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# inverse transform of empty array is empty array\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1367\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1356\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1357\u001b[0m             (\n\u001b[1;32m   1358\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1363\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1364\u001b[0m         )\n\u001b[1;32m   1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m-> 1367\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1368\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[1;32m   1369\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (10523, 3) instead."
     ]
    }
   ],
   "source": [
    "test_predictions_encoded = rf_model.predict(test_embeddings.numpy())\n",
    "test_predictions = label_encoder.inverse_transform(test_predictions_encoded)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'Target': test_predictions\n",
    "})\n",
    "submission.head()\n",
    "# submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize(project='gradient-growers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude = 115.794902228198879\n",
    "latitude = -1.629352395440254\n",
    "\n",
    "point = ee.Geometry.Point(longitude, latitude)\n",
    "start_date = '2024-01-01'\n",
    "end_date = '2024-01-31'\n",
    "\n",
    "# Example: Accessing Sentinel-2 Surface Reflectance data\n",
    "collection = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') \\\n",
    "    .filterBounds(point) \\\n",
    "    .filterDate(start_date, end_date) \\\n",
    "    .sort('CLOUDY_PIXEL_PERCENTAGE') \\\n",
    "    .first() # Get the least cloudy image\n",
    "\n",
    "if collection:\n",
    "    # Select specific bands (e.g., B4=Red, B3=Green, B2=Blue, B8=NIR for Sentinel-2)\n",
    "    # Apply scaling factors if necessary (often provided in dataset metadata)\n",
    "    # For Sentinel-2 SR, reflectance values are 10000 * actual reflectance\n",
    "    bands_of_interest = ['B2', 'B3', 'B4', 'B8']\n",
    "    image_at_point = collection.select(bands_of_interest).sample(point, scale=10).first()\n",
    "\n",
    "    # Get the band values at the point\n",
    "    data = image_at_point.getInfo()\n",
    "    print(f\"Band data at ({latitude}, {longitude}):\")\n",
    "    for band in bands_of_interest:\n",
    "        if band in data['properties']:\n",
    "            value = data['properties'][band]\n",
    "            print(f\"{band}: {value / 10000.0}\") # Scale back to actual reflectance\n",
    "else:\n",
    "    print(\"No image found for the specified location and time range.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting data from cocoa .tif\n",
    "import rasterio\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "CIV_cocao = 'Zindi\\Cocoa\\Detected_Cocoa_Farms\\Detected Cocoa Farms\\CIVKakao.tif'\n",
    "GHA_cocao = 'Zindi\\Cocoa\\Detected_Cocoa_Farms\\Detected Cocoa Farms\\GHAKakao.tif'\n",
    "try:\n",
    "        with rasterio.open(CIV_cocao) as src:\n",
    "                band_data = src.read(1)\n",
    "                print(f'CIV - Coordinate Reference System (CRS): {src.crs}')\n",
    "                pyplot.imshow(band_data, cmap='pink')\n",
    "                pyplot.show()\n",
    "        with rasterio.open(GHA_cocao) as src:\n",
    "                band_data = src.read(1)\n",
    "                print(f'GHA - Coordinate Reference System (CRS): {src.crs}')\n",
    "except rasterio.errors.RasterioIOError as e:\n",
    "        print(f'Error opening or reading GeoTIFF file: {e}')\n",
    "except Exception as e:\n",
    "        print(f'An unexpected error occurred: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CIV_cocao = 'Zindi/Cocoa/Detected_Cocoa_Farms/Detected Cocoa Farms/CIVKakao.tif'\n",
    "\n",
    "try:\n",
    "    with rasterio.open(CIV_cocao) as src:\n",
    "        # Set a scale factor, e.g. 0.1 means 10% of the original resolution\n",
    "        scale = 0.001\n",
    "        out_shape = (\n",
    "            1,\n",
    "            int(src.height * scale),\n",
    "            int(src.width * scale)\n",
    "        )\n",
    "\n",
    "        band_data = src.read(\n",
    "            1,\n",
    "            out_shape=out_shape,\n",
    "            resampling=Resampling.nearest\n",
    "        )\n",
    "\n",
    "        transform = src.transform * src.transform.scale(\n",
    "            (src.width / band_data.shape[1]),\n",
    "            (src.height / band_data.shape[0])\n",
    "        )\n",
    "\n",
    "        print(f'CIV - Coordinate Reference System (CRS): {src.crs}')\n",
    "\n",
    "        rows, cols = np.nonzero(band_data)\n",
    "        lons, lats = rasterio.transform.xy(transform, rows, cols)\n",
    "        df = pd.DataFrame({'Longitude': lons, 'Latitude': lats})\n",
    "        print(df.head())\n",
    "        df.to_csv('CIVKokao_coordinates_downsampled.csv', index=False)\n",
    "\n",
    "except rasterio.errors.RasterioIOError as e:\n",
    "    print(f'Error opening or reading GeoTIFF file: {e}')\n",
    "except Exception as e:\n",
    "    print(f'An unexpected error occurred: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "GHA_cocao = 'Zindi/Cocoa/Detected_Cocoa_Farms/Detected Cocoa Farms/GHAKakao.tif'\n",
    "\n",
    "try:\n",
    "    with rasterio.open(GHA_cocao) as src:\n",
    "        # Set a scale factor, e.g. 0.1 means 10% of the original resolution\n",
    "        scale = 0.001\n",
    "        out_shape = (\n",
    "            1,\n",
    "            int(src.height * scale),\n",
    "            int(src.width * scale)\n",
    "        )\n",
    "\n",
    "        band_data = src.read(\n",
    "            1,\n",
    "            out_shape=out_shape,\n",
    "            resampling=Resampling.nearest\n",
    "        )\n",
    "\n",
    "        transform = src.transform * src.transform.scale(\n",
    "            (src.width / band_data.shape[1]),\n",
    "            (src.height / band_data.shape[0])\n",
    "        )\n",
    "\n",
    "        print(f'GHA - Coordinate Reference System (CRS): {src.crs}')\n",
    "\n",
    "        rows, cols = np.nonzero(band_data)\n",
    "        lons, lats = rasterio.transform.xy(transform, rows, cols)\n",
    "        df = pd.DataFrame({'Longitude': lons, 'Latitude': lats})\n",
    "        print(df.head())\n",
    "        df.to_csv('GHAKokao_coordinates_downsampled.csv', index=False)\n",
    "\n",
    "except rasterio.errors.RasterioIOError as e:\n",
    "    print(f'Error opening or reading GeoTIFF file: {e}')\n",
    "except Exception as e:\n",
    "    print(f'An unexpected error occurred: {e}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
